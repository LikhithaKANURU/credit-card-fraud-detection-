{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "18rGf7FP5AEU6h79M5tBsAX554D8UYIfe",
      "authorship_tag": "ABX9TyPXG3lFSesaeIoLbYj+T422",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LikhithaKANURU/credit-card-fraud-detection-/blob/main/CREDIT_CARD_FRAUD_DETECTIONS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**VERGEO PROJECT**\n",
        "# Minor Project\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GNzliFAZRzoB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1.PROBLEM STATEMENT**\n",
        "\n",
        "> Indented block\n",
        "\n",
        "\n",
        "\n",
        "## Credit Card Fraud Detection \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qdWRYsK4RyZv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.EXPLORATORY DATA ANALYSIS**\n",
        "# Introduction:\n",
        "*   When we make any transaction while purchasing any product online, a good amount of people prefer credit cards.\n",
        "* A high credit limit in credit cards sometimes helps us making expensive purchases even if we don’t have the savings at that time.\n",
        "*   But, on the other hand, these features are misused by cyber attackers.\n",
        "*   In order to tackle such a problem, a system needs to be built which can classify such transactions based on its characteristics and mark them fraudulent for the bank officials to act upon.\n",
        "\n",
        "hence this is the major task to predict fraudulent transactions for the given dataset "
      ],
      "metadata": {
        "id": "oSb8go4QPLPj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What do you mean credit card fraud?\n",
        "\n",
        "*   Credit card fraud is the most common type of identity theft. Millions of \n",
        "people fall victim every year.\n",
        "\n",
        "*   Some criminals use lost or stolen credit cards to commit fraud. Others make illegal transactions without ever having the credit card in their possession. Card-not-present fraud only requires the criminal to know basic card or account details to access the victim's funds."
      ],
      "metadata": {
        "id": "IK_EyU-xRx4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For doimg the explanatory data analysis we need to import libraries first"
      ],
      "metadata": {
        "id": "cWISxpZAl6-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing Libraries**\n"
      ],
      "metadata": {
        "id": "vDGRc992PNf0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "   # 1.WhaLibrariest Are ?\n",
        "\n",
        "* A library is a collection of functions that can be added to your Python code and called as necessary, just like any other function. There is no reason to rewrite code that will perform a standard task. With libraries, we can import pre-existing functions and efficiently expand the functionality of our code.\n",
        "\n",
        "\n",
        "\n",
        "*   Using the  import  keyword at the top of our code file, we can import certain library functions or the entire library at once. \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RdNnrakRUFDe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02qfWtn83YrN"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "import matplotlib.patches as mpatches\n",
        "import time\n",
        "\n",
        "# Classifier Libraries\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import collections\n",
        "\n",
        "\n",
        "# Other Libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from imblearn.metrics import classification_report_imbalanced\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data** **Processing**"
      ],
      "metadata": {
        "id": "dr_wvtbWNcHc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "* Now in this step we are going to lode the given credit card data set (CSV) into a veriable cred_card_fraud.\n",
        "\n",
        "\n",
        "* ***variable*** : \n",
        " Variables are containers for storing data values."
      ],
      "metadata": {
        "id": "aFxL6oQUVrNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the dataset to a Pandas Dataframe\n",
        "\n",
        "credit_card_data = pd.read_csv('/content/drive/MyDrive/card_transdata.csv')"
      ],
      "metadata": {
        "id": "C0aFBST54m1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3.Shape of the given dataset**"
      ],
      "metadata": {
        "id": "nfV40xZraTma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "credit_card_data.shape"
      ],
      "metadata": {
        "id": "-ayxF_3faRj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4.Displaying first 10 rows & columns of dataset**"
      ],
      "metadata": {
        "id": "33_AbV3_axLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see first 5 rows of the dataset:\n",
        "credit_card_data.head(10)"
      ],
      "metadata": {
        "id": "myE9ojnw5PBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see first 5 rows of the dataset:\n",
        "credit_card_data.tail(10)"
      ],
      "metadata": {
        "id": "rv8ayUcL5Qc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.Data types of all columns**"
      ],
      "metadata": {
        "id": "eFhcUR-XbdoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset information: \n",
        "credit_card_data.info() "
      ],
      "metadata": {
        "id": "6K1Z4Of65m-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Looking unique values\n",
        "print(credit_card_data.nunique())"
      ],
      "metadata": {
        "id": "VKbPPP0tOWyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#describing the given dataset \n",
        "credit_card_data.describe()"
      ],
      "metadata": {
        "id": "iR-3p7qT6JOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6.Statistical analysis of given dataset** "
      ],
      "metadata": {
        "id": "wSTv2acpeCF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation matrix\n",
        "corrmat = credit_card_data.corr()\n",
        "fig = plt.figure(figsize = (12, 9))\n",
        "sns.heatmap(corrmat, vmax = .8, square = True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jlnTAit2eFSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7.Handling missing values**"
      ],
      "metadata": {
        "id": "vh-H37jfeAux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "credit_card_data.columns"
      ],
      "metadata": {
        "id": "zvVz8TmU6NyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking number of missing values:\n",
        "credit_card_data_missing_values = credit_card_data.isnull().sum()\n",
        "credit_card_data_missing_values"
      ],
      "metadata": {
        "id": "jnRFZmWqOxVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Good No Null Values!\n",
        "credit_card_data .isnull().sum().max()"
      ],
      "metadata": {
        "id": "kkoMcl8RO_lQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8.Distribution of target variables**"
      ],
      "metadata": {
        "id": "Hqfte9hIX4HZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The data are heavily skewed we need to solve this issue later.\n",
        "print('No Frauds', round(credit_card_data['fraud'].value_counts()[0]/len(credit_card_data) * 100,2), '% of the dataset')\n",
        "print('Frauds', round(credit_card_data['fraud'].value_counts()[1]/len(credit_card_data) * 100,2), '% of the dataset')"
      ],
      "metadata": {
        "id": "XjRVkm-S6diG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "credit_card_data['fraud'].value_counts()"
      ],
      "metadata": {
        "id": "PBXAhpyWMGWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colors = [\"#0101DF\", \"#DF0101\"]\n",
        "\n",
        "sns.countplot('fraud', data=credit_card_data, palette=colors)\n",
        "plt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)"
      ],
      "metadata": {
        "id": "Un1_caOv7fjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_fraud = credit_card_data[credit_card_data['fraud'] == 1]\n",
        "data_non_fraud = credit_card_data[credit_card_data['fraud'] == 0] "
      ],
      "metadata": {
        "id": "L-bjwHMP7nuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9.Distribution of all variables**"
      ],
      "metadata": {
        "id": "6DtXezu6YNas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 3, figsize=(18,4))\n",
        "\n",
        "used_pin_number = credit_card_data['used_pin_number'].values\n",
        "repeat_retailer = credit_card_data['repeat_retailer'].values\n",
        "ratio_to_median_purchase_price = credit_card_data['ratio_to_median_purchase_price'].values\n",
        "\n",
        "sns.distplot(repeat_retailer, ax=ax[0], color='black')\n",
        "ax[0].set_title('Distribution of Transaction \\nrepeat_retailer', fontsize=14)\n",
        "ax[0].set_xlim([min(repeat_retailer), max(repeat_retailer)])\n",
        "\n",
        "sns.distplot(ratio_to_median_purchase_price, ax=ax[1], color='#FF6103')\n",
        "ax[1].set_title('Distribution of Transaction \\nratio_to_median_purchase_price', fontsize=14)\n",
        "ax[1].set_xlim([min(ratio_to_median_purchase_price), max(ratio_to_median_purchase_price)])\n",
        "\n",
        "sns.distplot(used_pin_number, ax=ax[2], color='#FF34B3')\n",
        "ax[2].set_title('Distribution of Transaction \\nused_pin_number', fontsize=14)\n",
        "ax[2].set_xlim([min(used_pin_number), max(used_pin_number)])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "02l4nILGJzCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 3, figsize=(18,4))\n",
        "\n",
        "used_chip = credit_card_data['used_chip'].values\n",
        "online_order = credit_card_data['online_order'].values\n",
        "distance_from_last_transaction = credit_card_data['distance_from_last_transaction'].values\n",
        "\n",
        "sns.distplot(online_order, ax=ax[1], color='red')\n",
        "ax[1].set_title('Distribution of Transaction \\n online_order', fontsize=14)\n",
        "ax[1].set_xlim([min(online_order), max(online_order)])\n",
        "\n",
        "sns.distplot(distance_from_last_transaction, ax=ax[2], color='#9932CC')\n",
        "ax[2].set_title('Distribution of Transaction \\ndistance_from_last_transaction', fontsize=14)\n",
        "ax[2].set_xlim([min(distance_from_last_transaction), max(distance_from_last_transaction)])\n",
        "\n",
        "sns.distplot(used_chip, ax=ax[0], color='green')\n",
        "ax[0].set_title('Distribution of Transaction \\nused_chip', fontsize=14)\n",
        "ax[0].set_xlim([min(used_chip), max(used_chip)])\n",
        "\n",
        "\n",
        "plt.show() "
      ],
      "metadata": {
        "id": "kscKyAR5QDON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **initializing**"
      ],
      "metadata": {
        "id": "BKLvCDwlzHYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Since our classes are highly skewed we should make them equivalent in order to have a normal distribution of the classes.\n",
        "\n",
        "# Lets shuffle the data before creating the subsamples\n",
        "\n",
        "credit_card_data = credit_card_data.sample(frac=1)\n",
        "\n",
        "# amount of fraud classes 492 rows.\n",
        "fraud_df = credit_card_data.loc[credit_card_data['fraud'] == 1]\n",
        "non_fraud_df = credit_card_data.loc[credit_card_data['fraud'] == 0][:492]\n",
        "\n",
        "normal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n",
        "\n",
        "# Shuffle dataframe rows\n",
        "new_df = normal_distributed_df.sample(frac=1, random_state=42)\n",
        "\n",
        "new_df.head()\n"
      ],
      "metadata": {
        "id": "AYdHPqK21GGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Distribution of the Classes in the subsample dataset')\n",
        "print(new_df['fraud'].value_counts()/len(new_df))\n",
        "\n",
        "\n",
        "\n",
        "sns.countplot('fraud', data=new_df, palette=colors)\n",
        "plt.title('Equally Distributed fraud and non fraud', fontsize=14)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HSUo3f4L1jEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10.Boxplots**\n",
        "*  A box plot is a good way to show many important features of quantitative \n",
        "(numerical) data.\n",
        "\n",
        "*  It shows the median of the data. This is the middle value of the data and one type of an average value.\n",
        "\n",
        "*  It also shows the range and the quartiles of the data. This tells us something about how spread out the data is."
      ],
      "metadata": {
        "id": "DPmgzwHm4ZsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f, axes = plt.subplots(ncols=7, figsize=(20,4))\n",
        "\n",
        "# Positive correlations (The higher the feature the probability increases that it will be a fraud transaction)\n",
        "sns.boxplot(x=\"fraud\", y=\"distance_from_home\", data=new_df, palette=colors, ax=axes[0])\n",
        "axes[0].set_title('distance_from_home \\nvs \\nfraud')\n",
        "\n",
        "sns.boxplot(x=\"fraud\", y=\"distance_from_last_transaction\", data=new_df, palette=colors, ax=axes[1])\n",
        "axes[1].set_title('distance_from_\\nlast_transaction\\n vs \\nfraud')\n",
        "\n",
        "\n",
        "sns.boxplot(x=\"fraud\", y=\"ratio_to_median_purchase_price\", data=new_df, palette=colors, ax=axes[2])\n",
        "axes[2].set_title('ratio_to_median_\\npurchase_price \\nvs\\n fraud')\n",
        "\n",
        "\n",
        "sns.boxplot(x=\"fraud\", y=\"repeat_retailer\", data=new_df, palette=colors, ax=axes[3])\n",
        "axes[3].set_title('repeat_retailer\\n vs \\nfraud')\n",
        "\n",
        "sns.boxplot(x=\"fraud\", y=\"used_chip\", data=new_df, palette=colors, ax=axes[4])\n",
        "axes[4].set_title('used_chip\\n vs \\nfraud')\n",
        "\n",
        "sns.boxplot(x=\"fraud\", y=\"used_pin_number\", data=new_df, palette=colors, ax=axes[5])\n",
        "axes[5].set_title('used_pin_number\\n vs \\nfraud')\n",
        "\n",
        "sns.boxplot(x=\"fraud\", y=\"online_order\", data=new_df, palette=colors, ax=axes[6])\n",
        "axes[6].set_title('online_order\\n vs \\nfraud')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6j-nYRe448xN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11.Outlier's**\n",
        "*     An outlier is a data point in a data set that is distant from all other observation. A data point that lies outside the overall distribution of dataset."
      ],
      "metadata": {
        "id": "8KJ4BAiA8yxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import norm\n",
        "\n",
        "f, (ax1, ax2, ax3,ax4,ax5,ax6,ax7) = plt.subplots(1,7, figsize=(20, 6))\n",
        "\n",
        "distance_from_home_fraud_dist = new_df['distance_from_home'].loc[new_df['fraud'] == 1].values\n",
        "sns.distplot(distance_from_home_fraud_dist,ax=ax1, fit=norm, color='black')\n",
        "ax1.set_title('distance_\\nfrom_home \\nDistribution \\n (Fraud Transactions)', fontsize=14)\n",
        "\n",
        "distance_from_last_transaction_fraud_dist = new_df['distance_from_last_transaction'].loc[new_df['fraud'] == 1].values\n",
        "sns.distplot(distance_from_last_transaction_fraud_dist,ax=ax2, fit=norm, color='#56F9BB')\n",
        "ax2.set_title('distance_\\nfrom_last_\\ntransaction\\n Distribution \\n (Fraud Transactions)', fontsize=14)\n",
        "\n",
        "\n",
        "ratio_to_median_purchase_price_fraud_dist = new_df['ratio_to_median_purchase_price'].loc[new_df['fraud'] == 1].values\n",
        "sns.distplot(ratio_to_median_purchase_price_fraud_dist,ax=ax3, fit=norm, color='purple')\n",
        "ax3.set_title('ratio_to_\\nmedian_purchase\\n_price\\n Distribution \\n (Fraud Transactions)', fontsize=14)\n",
        "\n",
        "\n",
        "repeat_retailer_fraud_dist = new_df['repeat_retailer'].loc[new_df['fraud'] == 1].values\n",
        "sns.distplot(repeat_retailer_fraud_dist,ax=ax4, fit=norm, color='red')\n",
        "ax4.set_title(' repeat_retailer\\nDistribution \\n (Fraud Transactions)', fontsize=14)\n",
        "\n",
        "used_chip_fraud_dist = new_df['used_chip'].loc[new_df['fraud'] == 1].values\n",
        "sns.distplot(used_chip_fraud_dist,ax=ax5, fit=norm, color='#8B795E')\n",
        "ax5.set_title('used_chip\\n Distribution \\n (Fraud Transactions)', fontsize=14)\n",
        "\n",
        "used_pin_number_fraud_dist = new_df['used_pin_number'].loc[new_df['fraud'] == 1].values\n",
        "sns.distplot(used_pin_number_fraud_dist,ax=ax6, fit=norm, color='#FF4500')\n",
        "ax6.set_title('used_pin_number\\n Distribution \\n (Fraud Transactions)', fontsize=14)\n",
        "\n",
        "online_order_fraud_dist = new_df['online_order'].loc[new_df['fraud'] == 1].values\n",
        "sns.distplot(online_order_fraud_dist,ax=ax7, fit=norm, color='blue')\n",
        "ax7.set_title('online_order\\n Distribution \\n (Fraud Transactions)', fontsize=14)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "msA6Bs-688LC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **12.Correlation Heatmaps**\n",
        "\n",
        "*   The heatmap is used to represent matrix values graphically with different color shades for different values. It visualizes the overall matrix very clearly.\n",
        "\n"
      ],
      "metadata": {
        "id": "6q5BHe2535qK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we use the subsample in our correlation\n",
        "\n",
        "f, (ax1, ax2) = plt.subplots(2, 1, figsize=(24,20))\n",
        "\n",
        "# Entire DataFrame\n",
        "corr = credit_card_data.corr()\n",
        "sns.heatmap(corr, cmap='coolwarm_r', annot_kws={'size':20}, ax=ax1)\n",
        "ax1.set_title(\"Imbalanced Correlation Matrix \\n (don't use for reference)\", fontsize=14)\n",
        "\n",
        "\n",
        "sub_sample_corr = new_df.corr()\n",
        "sns.heatmap(sub_sample_corr, cmap='coolwarm_r', annot_kws={'size':20}, ax=ax2)\n",
        "ax2.set_title('SubSample Correlation Matrix \\n (use for reference)', fontsize=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aOlRzO6-2MF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dividing the X and the Y from the dataset\n",
        "X=credit_card_data.drop(['fraud'], axis = 1)\n",
        "Y = credit_card_data[\"fraud\"]\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "# getting just the values for the sake of processing\n",
        "# (its a numpy array with no columns)\n",
        "xData = X.values\n",
        "yData = Y.values\n"
      ],
      "metadata": {
        "id": "i42-Zir416_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **14.Training and Testing Data Bifurcation**\n",
        "We will be dividing the dataset into two main groups. One for training the model and the other for Testing our trained model’s performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "fb2gyqh_2gG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Scikit-learn to split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Split the data into training and testing sets\n",
        "xTrain, xTest, yTrain, yTest = train_test_split(\n",
        "\t\txData, yData, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "SbIhBgkU2fnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a Random Forest Model using scikit learn\n"
      ],
      "metadata": {
        "id": "69l30BZo26HG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Random Forest Classifier (RANDOM FOREST)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# random forest model creation\n",
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(xTrain, yTrain)\n",
        "# predictions\n",
        "yPred = rfc.predict(xTest)"
      ],
      "metadata": {
        "id": "kU2_Lii021i3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Building all kinds of evaluating parameters\n"
      ],
      "metadata": {
        "id": "xmxDPIHQ3itP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fraud = credit_card_data[credit_card_data['fraud'] == 1]\n"
      ],
      "metadata": {
        "id": "BJulvXMW4CVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the classifier\n",
        "# printing every score of the classifier\n",
        "# scoring in anything\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import f1_score, matthews_corrcoef\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "n_outliers = len(fraud)\n",
        "n_errors = (yPred != yTest).sum()\n",
        "print(\"The model used is Random Forest classifier\")\n",
        "\n",
        "acc = accuracy_score(yTest, yPred)\n",
        "print(\"The accuracy is {}\".format(acc))\n",
        "\n",
        "prec = precision_score(yTest, yPred)\n",
        "print(\"The precision is {}\".format(prec))\n",
        "\n",
        "rec = recall_score(yTest, yPred)\n",
        "print(\"The recall is {}\".format(rec))\n",
        "\n",
        "f1 = f1_score(yTest, yPred)\n",
        "print(\"The F1-Score is {}\".format(f1))\n",
        "\n",
        "MCC = matthews_corrcoef(yTest, yPred)\n",
        "print(\"The Matthews correlation coefficient is{}\".format(MCC))\n"
      ],
      "metadata": {
        "id": "R9a4Sifi3F-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **15. Visualizing the Confusion Matrix**\n",
        "\n"
      ],
      "metadata": {
        "id": "ig_YlyC54f2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the confusion matrix\n",
        "LABELS = ['Normal', 'Fraud']\n",
        "conf_matrix = confusion_matrix(yTest, yPred)\n",
        "plt.figure(figsize =(12, 12))\n",
        "sns.heatmap(conf_matrix, xticklabels = LABELS,\n",
        "\t\t\tyticklabels = LABELS, annot = True, fmt =\"d\");\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.ylabel('True class')\n",
        "plt.xlabel('Predicted class')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fqN3WQmG4b5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusions**\n",
        "This tutorial trained different classifiers and performed undersampling and oversampling techniques after splitting the data into training and test sets to decide which classifier is more effective in detecting fraudulent transactions.\n",
        "\n"
      ],
      "metadata": {
        "id": "yT4bs39_bi9N"
      }
    }
  ]
}